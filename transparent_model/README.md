# Transparent/Interpretable Model

This family of models is self-explained and transparent to users. 

## Papers

[On the Power of Decision Trees in Auto-Regressive Language Modeling](https://www.arxiv.org/abs/2409.19150#:~:text=On%20the%20Power%20of%20Decision%20Trees%20in%20Auto%2DRegressive%20Language%20Modeling,-Yulu%20Gan%2C%20Tomer&text=Originally%20proposed%20for%20handling%20time,ARDTs%20in%20this%20new%20context.), NeurIPS 2024

[PICNN: A Pathway towards Interpretable Convolutional Neural Networks](https://ojs.aaai.org/index.php/AAAI/article/view/27971/27960), AAAI 2024

[A Convolutional Neural Network Interpretable Framework for Human Ventral Visual Pathway Representation](https://ojs.aaai.org/index.php/AAAI/article/view/28461), AAAI 2024

[Self-Interpretable Graph Learning with Sufficient and Necessary Explanations](https://ojs.aaai.org/index.php/AAAI/article/view/29059/30007), AAAI 2024

[Learning Performance Maximizing Ensembles with Explainability Guarantees](https://ojs.aaai.org/index.php/AAAI/article/view/29378/30602), AAAI 2024

[NeSyFOLD: A Framework for Interpretable Image Classification](https://ojs.aaai.org/index.php/AAAI/article/view/28235/28465), AAAI 2024

[Pantypes: Diverse Representatives for Self-Explainable Models](https://arxiv.org/abs/2403.09383), AAAI 2024

[Towards Modeling Uncertainties of Selfexplaining Neural Networks](https://ojs.aaai.org/index.php/AAAI/article/view/29382/30610), AAAI 2024

[FEAMOE: Fair, Explainable and Adaptive Mixture of Experts](https://www.ijcai.org/proceedings/2023/0055.pdf), IJCAI 2023

[Bort: Towards Explainable Neural Networks with Bounded Orthogonal Constraint](https://openreview.net/forum?id=My57qBufZWs), ICLR 2023

[A Framework for Learning Ante-hoc Explainable Models via Concepts](https://openaccess.thecvf.com/content/CVPR2022/papers/Sarkar_A_Framework_for_Learning_Ante-Hoc_Explainable_Models_via_Concepts_CVPR_2022_paper.pdf), CVPR 2022

[Explainable Reinforcement Learning via Model Transforms](https://openreview.net/pdf?id=32Ryt4pAHeD), NeurIPS 2022

[Visual correspondence-based explanations improve AI robustness and human-AI team accuracy](https://openreview.net/pdf?id=UavQ9HYye6n), NeurIPS 2022

[Decision Trees with Short Explainable Rules](https://openreview.net/pdf?id=Lp-QFq2QRXA), NeurIPS 2022

[Hierarchical Shrinkage:improving the accuracy and interpretability of tree-based methods](https://arxiv.org/pdf/2202.00858.pdf), ICML 2022

[Entropy-based Logic Explanations of Neural Networks](https://arxiv.org/pdf/2106.06804.pdf), AAAI 2022

[Scalable Rule-Based Representation Learning for Interpretable Classification](https://arxiv.org/abs/2109.15103), NeurIPS 2021

[Neural Additive Models: Interpretable Machine Learning with Neural Nets](https://arxiv.org/abs/2004.13912), NeurIPS 2021

[Self-Interpretable Model with TransformationEquivariant Interpretation](https://arxiv.org/abs/2111.04927), NeurIPS 2021

[Interpretable Compositional Convolutional Neural Networks](https://arxiv.org/pdf/2107.04474.pdf), IJCAI 2021

[Connecting Interpretability and Robustness in Decision Trees through Separation](https://arxiv.org/pdf/2102.07048.pdf), ICML 2021

[Explanation Consistency Training: Facilitating Consistency-Based Semi-Supervised Learning with Interpretability](https://cs.nju.edu.cn/liyf/paper/aaai21-ect.pdf), AAAI 2021

[TabNet: Attentive Interpretable Tabular Learning](https://arxiv.org/pdf/1908.07442.pdf), AAAI 2021

[Building Interpretable Interaction Trees for Deep NLP Mode](), AAAI 2021

[Shapley Explanation Networks](https://openreview.net/forum?id=vsU0efpivw), ICLR 2021

[NBDT: Neural-Backed Decision Trees](https://arxiv.org/abs/2004.00221), ICLR 2021

[Neural additive models: Interpretable machine learning with neural nets](https://arxiv.org/pdf/2004.13912.pdf), Arxiv preprint 2020

[Training Interpretable Convolutional Neural Networks by Differentiating Class-specific Filters](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470613.pdf), ECCV 2020

[Transparent Classification with Multilayer Logical Perceptrons and Random Binarization](https://arxiv.org/abs/1912.04695), AAAI 2020

[Generalized Linear Rule Models](http://proceedings.mlr.press/v97/wei19a/wei19a.pdf), ICML 2019

[Axiomatic Interpretability for Multiclass Additive Models](https://dl.acm.org/doi/pdf/10.1145/3292500.3330898), KDD 2019

[Interpretable Convolutional Neural Networks](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Interpretable_Convolutional_Neural_CVPR_2018_paper.pdf), CVPR 2018

[Boolean Decision Rules via Column Generation](https://papers.nips.cc/paper/2018/file/743394beff4b1282ba735e5e3723ed74-Paper.pdf), NIPS 2018

[Towards Robust Interpretability with Self-Explaining Neural Networks](https://papers.nips.cc/paper/2018/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf), NIPS 2018

[Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model](https://arxiv.org/abs/1511.01644), The Annals of Applied Statistics 2015

[Towards Robust Interpretability with Self-Explaining Neural Networks](https://proceedings.neurips.cc/paper/2018/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf), NeurIPS 2016

[Comprehensible Classification Models â€“ a position paper](https://www.kdd.org/exploration_files/V15-01-01-Freitas.pdf), KDD 2015

[Making machine learning models interpretable](https://pdfs.semanticscholar.org/ce0b/8b6fca7dc089548cc2e9aaac3bae82bb19da.pdf), ESANN 2012

[Predictive learning via rule ensembles](https://arxiv.org/abs/0811.1679), The Annals of Applied Statistics 2008

Other transparent models:
- Decision Tree
- Linear Models
- Rule-based Models
- K-NN
- General Additive Models(GAMs)
- RuleFit

